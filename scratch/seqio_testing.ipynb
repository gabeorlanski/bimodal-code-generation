{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272300fa-cce5-4128-9cab-55457554d6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-09 15:56:40.899945: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64\n",
      "2022-01-09 15:56:40.899958: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Using custom data configuration default-ef56cc1ea23e9418\n",
      "Reusing dataset json (/home/gabe/.cache/huggingface/datasets/json/default-ef56cc1ea23e9418/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323628516678473d836d59fbe47f7892",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seqio\n",
    "from seqio import Mapping\n",
    "import tensorflow.compat.v1 as tf\n",
    "from pathlib import Path\n",
    "from datasets import Dataset, load_dataset\n",
    "import datasets\n",
    "from transformers import AutoTokenizer\n",
    "ROOT = Path.cwd().parents[0]\n",
    "def feature_to_spec(feature, length=False):\n",
    "    if isinstance(feature, datasets.ClassLabel):\n",
    "        return tf.TensorSpec(shape=() if not length else (None if length == -1 else length,), dtype=tf.int64)\n",
    "    elif isinstance(feature, datasets.Value):\n",
    "        print(feature)\n",
    "        return tf.TensorSpec(\n",
    "            shape=() if not length else (None if length == -1 else length,), dtype=getattr(tf.dtypes, feature.dtype)\n",
    "        )\n",
    "    elif hasattr(feature, \"dtype\") and hasattr(feature, \"shape\"):\n",
    "        return tf.TensorSpec(shape=feature.shape, dtype=feature.dtype)\n",
    "    elif isinstance(feature, datasets.Sequence):\n",
    "        return feature_to_spec(feature.feature, length=feature.length)\n",
    "    elif isinstance(feature, list):\n",
    "        return [feature_to_spec(f, length=length) for f in feature]\n",
    "    elif isinstance(feature, dict):\n",
    "        return {k: feature_to_spec(v, length=length) for k, v in feature.items()}\n",
    "    else:\n",
    "        raise ValueError(f\"Unparseable feature type {type(feature)}\")\n",
    "        \n",
    "def hf_dataset_to_tf_dataset(dataset):\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        dataset.__iter__, output_signature={k: feature_to_spec(v) for k, v in dataset.features.items()}\n",
    "    )\n",
    "data_path = ROOT.joinpath('data','MBPP')\n",
    "dataset = load_dataset('json',data_files={'train':str(data_path.joinpath('train.jsonl')),\"validation\":str(data_path.joinpath('validation.jsonl'))})\n",
    "def get_tf_dataset(split, shuffle_files):\n",
    "    # HF datasets does not support file-level shuffling\n",
    "    del shuffle_files\n",
    "    \n",
    "    dataset = load_dataset('json',data_files={'train':str(data_path.joinpath('train.jsonl')),\"validation\":str(data_path.joinpath('validation.jsonl'))})\n",
    "    dataset = dataset.map(lambda x,idx: {'idx':idx,**{k:v for k,v in x.items() if k != 'challenge_test_list'}},with_indices=True, remove_columns=dataset['train'].column_names)\n",
    "    return hf_dataset_to_tf_dataset(dataset[split])\n",
    "\n",
    "@seqio.map_over_dataset\n",
    "def fix_col(\n",
    "    sample: Mapping[str, tf.Tensor]\n",
    ") -> Mapping[str, tf.Tensor]:\n",
    "    return {\n",
    "      'inputs': sample['text'],\n",
    "      'targets': sample['code'],\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f14cebaf-1648-470b-a807-994048228bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer= AutoTokenizer.from_pretrained('t5-base')\n",
    "vocab = list(tokenizer.vocab)\n",
    "\n",
    "split_mapping = {\"train\":\"train\",\"validation\":\"validation\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da24a6-05c9-446a-a5cb-ccb5ef5d727a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bd7b393-1052-4dbc-8135-e69dbccd01ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seqio.dataset_providers.Task at 0x7f5a359a8670>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_source = seqio.FunctionDataSource(\n",
    "        get_tf_dataset,\n",
    "        splits=list(split_mapping.keys()),\n",
    "        num_input_examples={s: len(dataset[split_mapping[s]]) for s in split_mapping.keys()},\n",
    "    )\n",
    "import os\n",
    "seqio_vocab = seqio.SentencePieceVocabulary(tokenizer.vocab_file,extra_ids=100)\n",
    "\n",
    "output_features = {\n",
    "    \"inputs\": seqio.Feature(seqio_vocab, add_eos=False, dtype=tf.int32),\n",
    "    \"targets\": seqio.Feature(seqio_vocab, add_eos=True, dtype=tf.int32),\n",
    "}\n",
    "preprocessors = [\n",
    "    fix_col,\n",
    "    seqio.preprocessors.tokenize,\n",
    "    seqio.preprocessors.append_eos,\n",
    "    seqio.CacheDatasetPlaceholder(required=False),\n",
    "]\n",
    "\n",
    "import sklearn.metrics\n",
    "def acc(targets,predictions):\n",
    "    return {\"accuracy\": 100*sklearn.metrics.accuracy_score(targets, predictions)}\n",
    "seqio.TaskRegistry.remove('testing')\n",
    "seqio.TaskRegistry.add(\n",
    "    \"testing\",\n",
    "    data_source,\n",
    "    preprocessors=preprocessors,\n",
    "    output_features=output_features,\n",
    "    metric_fns=[acc],\n",
    "    postprocess_fn=lambda f: f,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fc20ada-a64a-4252-a55b-52f1f6dc237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Using custom data configuration default-ef56cc1ea23e9418\n",
      "WARNING:datasets.builder:Reusing dataset json (/home/gabe/.cache/huggingface/datasets/json/default-ef56cc1ea23e9418/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d36e48111348b4b1285d796d030c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/gabe/.cache/huggingface/datasets/json/default-ef56cc1ea23e9418/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde/cache-461e9892fee8c859.arrow\n",
      "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /home/gabe/.cache/huggingface/datasets/json/default-ef56cc1ea23e9418/0.0.0/c90812beea906fcffe0d5e3bb9eba909a80a998b5f88e9f8acbd320aa91acfde/cache-7a15b83c028ea691.arrow\n",
      "INFO:absl:Automatically caching small dataset in memory: 'testing:train'\n",
      "WARNING:absl:Features not in `features_length` will be removed during packing: {'targets_pretokenized', 'inputs_pretokenized'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(dtype='string', id=None)\n",
      "Value(dtype='string', id=None)\n",
      "Value(dtype='int64', id=None)\n",
      "Value(dtype='string', id=None)\n",
      "Value(dtype='string', id=None)\n",
      "Value(dtype='int64', id=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:The output dataset from seqio.get_dataset has the following features\n",
      "INFO:absl:feature: encoder_input_tokens \t shape: [512] \t dtype: int32\n",
      "INFO:absl:feature: decoder_target_tokens \t shape: [512] \t dtype: int32\n",
      "INFO:absl:feature: decoder_input_tokens \t shape: [512] \t dtype: int32\n",
      "INFO:absl:feature: decoder_loss_weights \t shape: [512] \t dtype: int32\n",
      "INFO:absl:feature: encoder_segment_ids \t shape: [512] \t dtype: int32\n",
      "INFO:absl:feature: decoder_segment_ids \t shape: [512] \t dtype: int32\n",
      "INFO:absl:feature: encoder_positions \t shape: [512] \t dtype: int32\n",
      "INFO:absl:feature: decoder_positions \t shape: [512] \t dtype: int32\n"
     ]
    }
   ],
   "source": [
    "tf_dataset: tf.data.Dataset = seqio.get_dataset(\n",
    "    mixture_or_task_name=\"testing\",\n",
    "    task_feature_lengths={\"targets\": 512,\"inputs\":512},\n",
    "    dataset_split=\"train\",\n",
    "    shuffle=False,\n",
    "    feature_converter=seqio.EncDecFeatureConverter()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56eee71e-ef4c-4ee5-81de-0e713b560979",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3881999250.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_5787/3881999250.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    model =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a9e178f-1dd5-4896-8618-c2b8176cb098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'encoder_input_tokens': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "  array([ 8733,     3,     9,     3,   102,    63,   189,   106,  1681,\n",
       "            12,   253,  2559,  4505,    13,  2580,    13,     3,     9,\n",
       "           787,   381,     5,  8733,     3,     9,  1681,    12,  3476,\n",
       "             8,  3282,  7321,    16,     8,  4838,     3,  1496,  1054,\n",
       "             3,    17,   413,   109,     5,  8733,     3,     9,  1681,\n",
       "            12,  5755,     3,    17,   413,   109,   139,   570,    57,\n",
       "          2651,     8,   787,  6108,   227,   334,  3282,     5,  8733,\n",
       "             3,     9,  1681,    12,   253,     8,  4505,    51,   257,\n",
       "            13,     3,    17,   413,   109,  2479,    16,     8,   787,\n",
       "             3,    17,   413,   109,   570,     5,  8733,     3,     9,\n",
       "          1681,    12,   691,     3,    99,   132,    19,     3,     9,\n",
       "           769,  2244,    28,  4505,  1227, 23448,    57,     3,    51,\n",
       "             5,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        dtype=int32)>,\n",
       "  'decoder_target_tokens': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "  array([   20,    89,   253,   834, 12858,   834,   134,   440,   599,\n",
       "          5525,    61,    10,  4505,  3274,     3,   632,     3,    23,\n",
       "          3274,   204,   298,   599,    23,  1429,     3,    23,     3,\n",
       "             2,  2423,     3,  5525,    61,    10,   298,   599,  5525,\n",
       "             3,  1454,     3,    23,  3274,  2423,     3,   632,    61,\n",
       "            10,  4505,  1768,  2423,     3,    23,     3,  5525,     3,\n",
       "            87,  2423,     3,    23,     3,    23,  1768,  2423,   209,\n",
       "          4505,  1768,  2423,     3,  5525,  1205,  4505,     1,    20,\n",
       "            89,  2667,   324,   599,  4377,   834,    17,   413,   109,\n",
       "            61,    10,    21,     3,    17,   413,    16,   794,   834,\n",
       "            17,   413,   109,    10,     3,    99,    19,    77,  8389,\n",
       "           599,    17,   413,     6,     3,    17,   413,   109,    61,\n",
       "            10,  6339,    45,  2667,   324,   599,    17,   413,    61,\n",
       "          1307,    10,  6339,     3,    17,   413,    20,    89,  3476,\n",
       "           834,    15,  3335,   834,    89,    60,  1824,   599,  4377,\n",
       "           834,    17,   413,   109,    61,    10,     3,    60,     7,\n",
       "          3274,     3,     2,    21,     3,   400,    16,  2667,   324,\n",
       "           599,  4377,   834,    17,   413,   109,    61,    10,     3,\n",
       "            99,     3,   400,    59,    16,     3,    60,     7,    10,\n",
       "             3,    60,     7,  6306,   400,   908,  3274,     3,   632,\n",
       "             3,    60,     7,  6306,   400,   908,  1768,  2423,   209,\n",
       "          1205,    41,    60,     7,    61,     1,    20,    89,   617,\n",
       "           834,     7,    17,    52,   599,  4377,   834,    17,   413,\n",
       "             6,   480,    61,    10,     3,    60,     7,  3274,   784,\n",
       "           400,    21,   769,    16,   794,   834,    17,   413,    21,\n",
       "             3,   400,    16,    41,  7304,     6,   480,    61,   908,\n",
       "          1205,    41,    60,     7,    61,     1,    20,    89,  4505,\n",
       "           834,    15,  3335,     7,   599,  4377,   834,    17,   413,\n",
       "            61,    10,     3,    60,     7,  3274,  4505,   599,  3350,\n",
       "           599,  4377,   834,    17,   413,    61,    61,  1205,    41,\n",
       "            60,     7,    61,     1,    20,    89, 15741,   834,  4078,\n",
       "           599,   291,    52,     6,     3,    29,     6,     3,    51,\n",
       "            61,    10,     3,    99,    41,    29,  2490,     3,    51,\n",
       "            61,    10,  1205, 10998,     3,  7410,  3274,   784,   371,\n",
       "          5405,    15,    21,     3,    23,    16,   620,   599,    51,\n",
       "            61,   908,    21,     3,    23,    16,   620,   599,    29,\n",
       "            61,    10,     3,    99,    41,  7410,  6306,   632,   908,\n",
       "            61,    10,  1205, 10998, 10301,  3274,   784,   371,  5405,\n",
       "            15,    21,     3,    23,    16,   620,   599,    51,    61,\n",
       "           908,    21,     3,   354,    16,   620,   599,    51,    61,\n",
       "            10,     3,    99,    41,  7410,  6306,   354,   908,  3274,\n",
       "          2423, 10998,    61,    10,     3,    99,    41,  7410,  6306,\n",
       "           599,   354,  1768,  1584,    52,  6306,    23,   908,    61,\n",
       "             3,  1454,     3,    51,   908,  3274,  2423, 10747,     7,\n",
       "            15,    61,    10, 10301,  6306,   599,   354,  1768,  1584,\n",
       "            52,  6306,    23,   908,    61,     3,  1454,     3,    51,\n",
       "           908,  3274, 10998,    21,     3,   354,    16,   620,   599,\n",
       "            51,    61,    10,     3,    99,    41, 15076,  6306,   354,\n",
       "           908,    61,    10,     3,  7410,  6306,   354,   908,  3274,\n",
       "         10998,     3,  7410,  6306,   291,    52,  6306,    23,   908,\n",
       "             3,  1454,     3,    51,   908,  3274, 10998,  1205,     3,\n",
       "          7410,  6306,   632,   908,     1,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        dtype=int32)>,\n",
       "  'decoder_input_tokens': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "  array([    0,    20,    89,   253,   834, 12858,   834,   134,   440,\n",
       "           599,  5525,    61,    10,  4505,  3274,     3,   632,     3,\n",
       "            23,  3274,   204,   298,   599,    23,  1429,     3,    23,\n",
       "             3,     2,  2423,     3,  5525,    61,    10,   298,   599,\n",
       "          5525,     3,  1454,     3,    23,  3274,  2423,     3,   632,\n",
       "            61,    10,  4505,  1768,  2423,     3,    23,     3,  5525,\n",
       "             3,    87,  2423,     3,    23,     3,    23,  1768,  2423,\n",
       "           209,  4505,  1768,  2423,     3,  5525,  1205,  4505,     0,\n",
       "            20,    89,  2667,   324,   599,  4377,   834,    17,   413,\n",
       "           109,    61,    10,    21,     3,    17,   413,    16,   794,\n",
       "           834,    17,   413,   109,    10,     3,    99,    19,    77,\n",
       "          8389,   599,    17,   413,     6,     3,    17,   413,   109,\n",
       "            61,    10,  6339,    45,  2667,   324,   599,    17,   413,\n",
       "            61,  1307,    10,  6339,     3,    17,   413,    20,    89,\n",
       "          3476,   834,    15,  3335,   834,    89,    60,  1824,   599,\n",
       "          4377,   834,    17,   413,   109,    61,    10,     3,    60,\n",
       "             7,  3274,     3,     2,    21,     3,   400,    16,  2667,\n",
       "           324,   599,  4377,   834,    17,   413,   109,    61,    10,\n",
       "             3,    99,     3,   400,    59,    16,     3,    60,     7,\n",
       "            10,     3,    60,     7,  6306,   400,   908,  3274,     3,\n",
       "           632,     3,    60,     7,  6306,   400,   908,  1768,  2423,\n",
       "           209,  1205,    41,    60,     7,    61,     0,    20,    89,\n",
       "           617,   834,     7,    17,    52,   599,  4377,   834,    17,\n",
       "           413,     6,   480,    61,    10,     3,    60,     7,  3274,\n",
       "           784,   400,    21,   769,    16,   794,   834,    17,   413,\n",
       "            21,     3,   400,    16,    41,  7304,     6,   480,    61,\n",
       "           908,  1205,    41,    60,     7,    61,     0,    20,    89,\n",
       "          4505,   834,    15,  3335,     7,   599,  4377,   834,    17,\n",
       "           413,    61,    10,     3,    60,     7,  3274,  4505,   599,\n",
       "          3350,   599,  4377,   834,    17,   413,    61,    61,  1205,\n",
       "            41,    60,     7,    61,     0,    20,    89, 15741,   834,\n",
       "          4078,   599,   291,    52,     6,     3,    29,     6,     3,\n",
       "            51,    61,    10,     3,    99,    41,    29,  2490,     3,\n",
       "            51,    61,    10,  1205, 10998,     3,  7410,  3274,   784,\n",
       "           371,  5405,    15,    21,     3,    23,    16,   620,   599,\n",
       "            51,    61,   908,    21,     3,    23,    16,   620,   599,\n",
       "            29,    61,    10,     3,    99,    41,  7410,  6306,   632,\n",
       "           908,    61,    10,  1205, 10998, 10301,  3274,   784,   371,\n",
       "          5405,    15,    21,     3,    23,    16,   620,   599,    51,\n",
       "            61,   908,    21,     3,   354,    16,   620,   599,    51,\n",
       "            61,    10,     3,    99,    41,  7410,  6306,   354,   908,\n",
       "          3274,  2423, 10998,    61,    10,     3,    99,    41,  7410,\n",
       "          6306,   599,   354,  1768,  1584,    52,  6306,    23,   908,\n",
       "            61,     3,  1454,     3,    51,   908,  3274,  2423, 10747,\n",
       "             7,    15,    61,    10, 10301,  6306,   599,   354,  1768,\n",
       "          1584,    52,  6306,    23,   908,    61,     3,  1454,     3,\n",
       "            51,   908,  3274, 10998,    21,     3,   354,    16,   620,\n",
       "           599,    51,    61,    10,     3,    99,    41, 15076,  6306,\n",
       "           354,   908,    61,    10,     3,  7410,  6306,   354,   908,\n",
       "          3274, 10998,     3,  7410,  6306,   291,    52,  6306,    23,\n",
       "           908,     3,  1454,     3,    51,   908,  3274, 10998,  1205,\n",
       "             3,  7410,  6306,   632,   908,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        dtype=int32)>,\n",
       "  'decoder_loss_weights': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       "  'encoder_segment_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       "  'decoder_segment_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "  array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "         2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "         4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "         5, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
       "  'encoder_positions': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "  array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19, 20,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12,\n",
       "         13, 14, 15, 16, 17, 18, 19,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
       "         10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,  0,  1,  2,  3,  4,  5,\n",
       "          6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "         23, 24,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14,\n",
       "         15, 16, 17, 18, 19, 20, 21,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0], dtype=int32)>,\n",
       "  'decoder_positions': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
       "  array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "          52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "          65,  66,  67,  68,  69,  70,   0,   1,   2,   3,   4,   5,   6,\n",
       "           7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,  19,\n",
       "          20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
       "          33,  34,  35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,\n",
       "          46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
       "          59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71,\n",
       "          72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
       "          85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "          98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110,\n",
       "         111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123,\n",
       "           0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "          13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "          26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "          39,  40,  41,  42,  43,  44,   0,   1,   2,   3,   4,   5,   6,\n",
       "           7,   8,   9,  10,  11,  12,  13,  14,  15,  16,  17,  18,  19,\n",
       "          20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,\n",
       "          33,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,\n",
       "          12,  13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,\n",
       "          25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,\n",
       "          38,  39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,\n",
       "          51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,\n",
       "          64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
       "          77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,\n",
       "          90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102,\n",
       "         103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115,\n",
       "         116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,\n",
       "         129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
       "         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
       "         155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
       "         168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
       "         181, 182, 183, 184, 185, 186, 187, 188, 189,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0], dtype=int32)>}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for _,x in zip(range(1),tf_dataset)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f576b7-f7b3-4585-b76a-d31f2a931a89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spring-research",
   "language": "python",
   "name": "spring-research"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
