defaults:
  - base_config
  - task: ???
  - objective: ???
  - _self_
  - objective: seq2seq

# Required Arguments
model: ???
model_path: null
is_checkpoint: false
project: "adversarial-code"


# General Arguments
data_path: data
device: cpu
seed: 1
numpy_seed: 2
pytorch_seed: 3

generation:
  max_length: 1024
  do_sample: true
  temperature: 0.5
  num_return_sequences: 2
  min_length: 75
  top_p: 0.95
  top_k: 50

training:
  batch_size: 1
  output_dir: models
  learning_rate: 5e-6
  logging_steps: 10
  warmup_ratio: 0.05
  weight_decay: 0.1
  gradient_accumulation_steps: 2
  lr_scheduler_type: 'polynomial'
  eval_accumulation_steps: 1
  metric_for_best_model: 'eval_loss'
  load_best_model_at_end: True
  save_total_limit: 2
  num_train_epochs: 10
  greater_is_better: False
  evaluation_strategy: epoch
  save_strategy: epoch
  group_by_length: True
  logging_first_step: True
  xpu_backend: "ccl"
  fp16: True
  disable_tqdm: True
  max_grad_norm: 1.0
  ddp_find_unused_parameters: False
#  deepspeed: ds_config.json

metrics:
  - exact-match
  - bleu
preprocessors:
  - add-prefix:
      prefix: "You are an expert Python programmer, and here is your task: "
  - add-suffix:
      suffix: "#Solution:\n"
      key: input_sequence