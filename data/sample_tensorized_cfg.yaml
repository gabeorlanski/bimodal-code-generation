data_args:
  seq_length: 256
data_path: data
debug: false
device: 0
generation:
  do_sample: true
  max_length: 256
  min_length: 75
  num_return_sequences: 25
  temperature: 0.5
  top_k: 50
  top_p: 0.95
group: SO
is_checkpoint: false
meta:
  ablation: PyOnlyCodeFullRepeat
  ablation_vals:
    DumpName: PyOnlyCodeFullRepeat
  card_name: ParrotSmall.SO
  step: PreTrain
metrics:
  - exact-match
  - bleu
model: EleutherAI/gpt-neo-125M
model_path: null
name: ConditionTest
numpy_seed: 2
objective: lm
postprocessors: [ ]
preprocessors: [ ]
processor:
  name: stackoverflow
  params:
    allow_no_answer: false
    answer_sorting: accepted
    answers_per_sample: -1
    bad_answer_cutoff: -1
    comment_type_for_question: NONE
    good_answer_cutoff: 3
    include_date: false
    include_question_score: false
    include_tags: false
    no_answer_str: There is not an answer
    prompt_file: templates/so/base_question.txt
    remove_modality: NONE
    repeat_body_for_each_answer: false
    repeat_prompt_each_answer: true
    top_answer_cutoff: 12
    wrap_answer_character: None

project: so-code-gen
pytorch_seed: 3
seed: 1
task:
  buffer_size: 2500
  ds_info_path: data/ds_info
  eval_splits: [ ]
  name: so
  raw_dump_name: python
  raw_dump_path: data/dumps
  seed: 1
  sequence_length: 1024
  tensorized_name: python_code_norepeat
tensorize_batch_size: 64
tracking:
  entity: nyu-code-research
  log_model: true
  project: so-code-gen
  watch: gradients
  tags:
   - Testing
training:
  batch_size: 32
  ddp_find_unused_parameters: false
  #  deepspeed: ds_config.json
  disable_tqdm: true
  dataloader_num_workers: 2
  eval_accumulation_steps: 1
  eval_steps: 250
  evaluation_strategy: steps
  fp16: true
  fp16_backend: apex
  fp16_opt_level: O2
  gradient_accumulation_steps: 2
  gradient_checkpointing: true
  greater_is_better: false
  group_by_length: false
  learning_rate: 0.0005
  load_best_model_at_end: false
  logging_first_step: true
  logging_steps: 25
  lr_scheduler_type: linear
  max_grad_norm: 1.0
  max_steps: 5000
  metric_for_best_model: eval_loss
  num_train_epochs: 1
  output_dir: models
  save_steps: 2500
  save_strategy: steps
  save_total_limit: 10
  warmup_ratio: 0.01
  warmup_steps: 250
  weight_decay: 0.1
  xpu_backend: ccl
  remove_unused_columns: false
  use_8bit_adam: True
