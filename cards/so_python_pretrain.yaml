starting_commands: command_templates/sbatch_experiment.txt
experiments:
  PretrainRaw.ParrotSmall:
    overrides:
      ++device: 0
      ++tracking:
        log_model: True
      model: 'lvwerra/codeparrot-small'
      train_batch_size: 16
      eval_batch_size: 16
      gradient_accumulation_steps: 4
      seq_length: 1024
      processor: stackoverflow
      lr: 1e-4
      save_steps: 2500
      max_steps: 10000
      warmup_steps: 500
    ablations:
      - DumpName:
          Python:
            dump_name: python
          Random:
            dump_name: random
      - Cleaning:
          Clean:
            ++processor.params.clean: True
          NoClean:
            ++processor.params.clean: False
    steps:
      - name: PreTrain
        base: pretrain
        group: SO
        overrides:
          tracking:
            log_model: true
    command:
      file: command_templates/deepspeed_pretrain.txt
      fields:
        - model_path