starting_commands: templates/commands/sbatch_experiment.txt
experiments:
#  QualityPromptAfter:
#    description: "Testing Different Quality Adjectives AFTER the text for evaluating the model finetuned on SO with Only Title and Repeating + Only Code Answer + The quality prompt"
#    overrides:
#      ++device: 0
#      +processor: stackoverflow
#      ++raw_dump_path: data/dumps
#      is_checkpoint: true
#      objective: lm
#      ++tracking.tags:
#        - O2
#        - Prompting
#      ++evaluation:
#        num_generate_per_step: 200
#        remove_input_ids: False
#        seq_per_sample: 200
#      ++task.dump_name: python_${..__META__.ablation.name}
#      ++task.raw_dump_name: python
#      ++task.tensorized_name: python_${..__META__.ablation.name}
#      ++processor.params.repeat_prompt_each_answer: True
#      ++processor.params.repeat_body_for_each_answer: False
#      ++prompts:
#        file: templates/so_prompts.yaml
#        prompts.pipe:
#          - quality_after
#      ++processor.params.remove_modality: "NL"
#    ablations:
#      - Model:
#          Neo125M:
#            description: GPT Neo 125M
#            overrides:
#              ++model: 'EleutherAI/gpt-neo-125M'
#              ++training.gradient_checkpointing: True
#            step_overrides:
#              PreTrain:
#                ++training.batch_size: 32
#                ++training.gradient_accumulation_steps: 1
#          ParrotSmall:
#            description: CodeParrot Small
#            overrides:
#              ++model: 'lvwerra/codeparrot-small'
#            step_overrides:
#              PreTrain:
#                ++training.batch_size: 32
#                ++training.gradient_accumulation_steps: 1
#                ++training.gradient_checkpointing: True
#      - QualityAdjective:
#          Best:
#            description: The 'BEST' adjective, should in theory do the best
#            ++prompts.params:
#              quality: BEST
#          Bad:
#            description: The 'BAD' adjective, should in theory do the worst
#            ++prompts.params:
#              quality: BAD
#          Worst:
#            description: The 'WORST' adjective, should have no effect b/c it was not used in training
#            ++prompts.params:
#              quality: WORST
#          Ok:
#            description: The 'OK' adjective, should have minimal effect b/c is neutral
#            ++prompts.params:
#              quality: OK
#          Good:
#            description: The 'GOOD' adjective, should have slight performance improvement
#            ++prompts.params:
#              quality: GOOD
#          Word:
#            description: A random word that should have minimal impact
#            ++prompts.params:
#              quality: WORD
#    steps:
#      - name: PreTrain
#        description: Finetune on the SO Data
#        add_name: False
#        base: pretrain
#        group: SO
#        overrides:
#          ++task.buffer_size: 5000
#          tracking:
#            log_model: True
#          is_checkpoint: true
#          ++task.sequence_length: 1024
#          task: so
#      - name: HEEval
#        add_name: False
#        description: Evaluate the model on HumanEval
#        base: mbpp_finetune
#        group: HUMAN_EVAL
#        overrides:
#          task: human_eval
#          ++is_checkpoint: true
#          ++model_path: outputs/so/PromptingTitleCodeRepeat.${..__META__.ablation.Model}.QualityAfter/best_model
#          tracking:
#            log_model: False
#            watch: null
#            watch: null
#      - name: FineTune
#        add_name: False
#        description: Finetune on the MBPP Data
#        base: mbpp_finetune
#        group: MBPP
#        overrides:
#          task: mbpp
#          ++is_checkpoint: True
#          ++model_path: outputs/so/PromptingTitleCodeRepeat.${..__META__.ablation.Model}.QualityAfter/best_model
#          tracking:
#            log_model: False
#            watch: null
#      - name: Eval
#        description: Evaluate the model
#        base: mbpp_finetune
#        group: MBPP
#        overrides:
#          task: mbpp
#          ++is_checkpoint: true
#          ++model_path: outputs/mbpp/QualityPrompt.${..__META__.ablation.name}/best_model
#          tracking:
#            log_model: False
#            watch: null
#    command:
#      file: templates/commands/mbpp_eval.txt
#      kwargs:
#        train_sbatch: train_single_gpu
#        finetune_time: "12:00:00"
#        use_cds: True
#      fields:
#        - model_path
  RankingPromptBefore:
    description: "Testing Different Relative Ranking Adjectives BEFORE the text"
    overrides:
      ++device: 0
      +processor: stackoverflow
      ++raw_dump_path: data/dumps
      is_checkpoint: true
      objective: lm
      ++tracking.tags:
        - O2
        - Prompting
      ++evaluation:
        num_generate_per_step: 200
        remove_input_ids: False
        seq_per_sample: 200
      ++task.dump_name: python_${..__META__.ablation.name}
      ++task.raw_dump_name: python
      ++task.tensorized_name: python_${..__META__.ablation.name}
      ++processor.params.repeat_prompt_each_answer: True
      ++processor.params.repeat_body_for_each_answer: False
      ++prompts:
        file: templates/so_prompts.yaml
        pipe:
          - quality_before
      ++processor.params.remove_modality: "NL"
    ablations:
      - Model:
          #          Neo125M:
          #            description: GPT Neo 125M
          #            overrides:
          #              ++model: 'EleutherAI/gpt-neo-125M'
          #              ++training.gradient_checkpointing: True
          #            step_overrides:
          #              PreTrain:
          #                ++training.batch_size: 32
          #                ++training.gradient_accumulation_steps: 1
          ParrotSmall:
            description: CodeParrot Small
            overrides:
              ++model: 'lvwerra/codeparrot-small'
            step_overrides:
              PreTrain:
                ++training.batch_size: 32
                ++training.gradient_accumulation_steps: 1
                ++training.gradient_checkpointing: True
      - QualityAdjective:
          Best:
            description: The 'BEST' adjective
            hypothesis: Should do the best
            ++prompts.params:
              quality: BEST
          2ND:
            description: The '2ND' adjective
            hypothesis: Should be only worse than BEST
            ++prompts.params:
              quality: 2ND
          3RD:
            description: The '3RD' adjective
            hypothesis: Should be only worse than BEST and 2ND
            ++prompts.params:
              quality: 3RD
    steps:
      - name: PreTrain
        description: Finetune on the SO Data
        add_name: False
        base: pretrain
        group: SO
        overrides:
          ++task.buffer_size: 5000
          tracking:
            log_model: True
          is_checkpoint: true
          ++task.sequence_length: 1024
          task: so
      - name: HEEval
        add_name: False
        description: Evaluate the model on HumanEval
        base: mbpp_finetune
        group: HUMAN_EVAL
        overrides:
          task: human_eval
          ++is_checkpoint: true
          ++model_path: outputs/so/PromptingTitleCodeRepeat.${..__META__.ablation.Model}.QualityBefore/best_model
          tracking:
            log_model: False
            watch: null
            watch: null
      - name: FineTune
        add_name: False
        description: Finetune on the MBPP Data
        base: mbpp_finetune
        group: MBPP
        overrides:
          task: mbpp
          ++is_checkpoint: True
          ++model_path: outputs/so/PromptingTitleCodeRepeat.${..__META__.ablation.Model}.QualityBefore/best_model
          tracking:
            log_model: False
            watch: null
      - name: Eval
        description: Evaluate the model
        base: mbpp_finetune
        group: MBPP
        overrides:
          task: mbpp
          ++is_checkpoint: true
          ++model_path: outputs/mbpp/QualityPrompt.${..__META__.ablation.name}/best_model
          tracking:
            log_model: False
            watch: null
    command:
      file: templates/commands/evaluate_model.txt
      kwargs:
        train_sbatch: train_single_gpu
        finetune_time: "12:00:00"
        use_cds: True
      fields:
        - model_path
#  RankingPromptBefore.Comment:
#    description: "Testing Different Relative Ranking Adjectives BEFORE the text"
#    overrides:
#      ++device: 0
#      +processor: stackoverflow
#      ++raw_dump_path: data/dumps
#      is_checkpoint: true
#      objective: lm
#      ++tracking.tags:
#        - O2
#        - Prompting
#      ++evaluation:
#        num_generate_per_step: 200
#        remove_input_ids: False
#        seq_per_sample: 200
#      ++task.dump_name: python_${..__META__.ablation.name}
#      ++task.raw_dump_name: python
#      ++task.tensorized_name: python_${..__META__.ablation.name}
#      ++processor.params.repeat_prompt_each_answer: True
#      ++processor.params.repeat_body_for_each_answer: False
#      ++prompts:
#        file: templates/so_prompts.yaml
#        pipe:
#          - comment_quality_before
#      ++processor.params.remove_modality: "NL"
#    ablations:
#      - Model:
##          Neo125M:
##            description: GPT Neo 125M
##            overrides:
##              ++model: 'EleutherAI/gpt-neo-125M'
##              ++training.gradient_checkpointing: True
##            step_overrides:
##              PreTrain:
##                ++training.batch_size: 32
##                ++training.gradient_accumulation_steps: 1
#          ParrotSmall:
#            description: CodeParrot Small
#            overrides:
#              ++model: 'lvwerra/codeparrot-small'
#            step_overrides:
#              PreTrain:
#                ++training.batch_size: 32
#                ++training.gradient_accumulation_steps: 1
#                ++training.gradient_checkpointing: True
#      - QualityAdjective:
#          Best:
#            description: The 'BEST' adjective
#            hypothesis: Should do the best
#            ++prompts.params:
#              quality: BEST
#          2ND:
#            description: The '2ND' adjective
#            hypothesis: Should be only worse than BEST
#            ++prompts.params:
#              quality: 2ND
#          3RD:
#            description: The '3RD' adjective
#            hypothesis: Should be only worse than BEST and 2ND
#            ++prompts.params:
#              quality: 3RD
#    steps:
#      - name: PreTrain
#        description: Finetune on the SO Data
#        add_name: False
#        base: pretrain
#        group: SO
#        overrides:
#          ++task.buffer_size: 5000
#          tracking:
#            log_model: True
#          is_checkpoint: true
#          ++task.sequence_length: 1024
#          task: so
#      - name: HEEval
#        add_name: False
#        description: Evaluate the model on HumanEval
#        base: mbpp_finetune
#        group: HUMAN_EVAL
#        overrides:
#          task: human_eval
#          ++is_checkpoint: true
#          ++model_path: outputs/so/PromptingTitleCodeRepeat.${..__META__.ablation.Model}.QualityBefore/best_model
#          tracking:
#            log_model: False
#            watch: null
#            watch: null
#      - name: FineTune
#        add_name: False
#        description: Finetune on the MBPP Data
#        base: mbpp_finetune
#        group: MBPP
#        overrides:
#          task: mbpp
#          ++is_checkpoint: True
#          ++model_path: outputs/so/PromptingTitleCodeRepeat.${..__META__.ablation.Model}.QualityBefore/best_model
#          tracking:
#            log_model: False
#            watch: null
#      - name: Eval
#        description: Evaluate the model
#        base: mbpp_finetune
#        group: MBPP
#        overrides:
#          task: mbpp
#          ++is_checkpoint: true
#          ++model_path: outputs/mbpp/QualityPrompt.${..__META__.ablation.name}/best_model
#          tracking:
#            log_model: False
#            watch: null
#    command:
#      file: templates/commands/human_eval.txt
#      kwargs:
#        train_sbatch: train_single_gpu
#        finetune_time: "12:00:00"
#        use_cds: True
#      fields:
#        - model_path