starting_commands: templates/commands/sbatch_experiment.txt
experiments:
  NoCarriageReturn:
    description: "Evaluate the baseline models with the updated MBPP loop"
    overrides:
      ++device: 0
      is_checkpoint: true
      objective: lm
      ++evaluation:
        num_generate_per_step: 200
        remove_input_ids: True
        seq_per_sample: 200
      ++task.params.remove_carriage_return: True
      tracking:
        tags: []
    ablations:
      - Model:
          ParrotSmall:
            description: CodeParrot Small
            overrides:
              ++model: 'lvwerra/codeparrot-small'
    steps:
      - name: FineTune
        add_name: False
        description: Finetune on the MBPP Data
        base: mbpp_finetune
        group: MBPP
        overrides:
          task: mbpp
          ++is_checkpoint: false
          ++model_path: null
          tracking:
            log_model: False
            watch: null
      - name: Eval
        add_name: False
        description: Evaluate the model
        base: mbpp_finetune
        group: MBPP
        overrides:
          task: mbpp
          ++is_checkpoint: true
          ++model_path: outputs/MBPP/${..__META__.ablation.Model}/best_model
          tracking:
            log_model: False
            watch: null
    command:
      file: templates/commands/mbpp_eval.txt
      kwargs:
        train_sbatch: train_single_gpu
        pretrain_time: "12:00:00"
        use_cds: True
      fields:
        - model_path