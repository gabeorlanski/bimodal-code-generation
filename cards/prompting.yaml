starting_commands: templates/commands/sbatch_experiment.txt
experiments:
  PromptingTitleRepeat:
    description: Test SO finetuning with Only Title and Repeating + different prompting methods
    overrides:
      ++device: 0
      +processor: stackoverflow
      ++raw_dump_path: data/dumps
      is_checkpoint: true
      objective: lm
      ++tracking.tags:
        - O2
        - Prompting
      ++batch_size: 200
      ++task.dump_name: python_${..__META__.ablation.name}
      ++task.raw_dump_name: python
      ++task.tensorized_name: python_${..__META__.ablation.name}
      ++processor.params.repeat_prompt_each_answer: True
      ++processor.params.repeat_body_for_each_answer: True
      ++prompts:
          file: templates/so_prompts.yaml
    ablations:
      - Model:
          Neo125M:
            description: GPT Neo 125M
            overrides:
              ++batch_size: 200
              ++model: 'EleutherAI/gpt-neo-125M'
            step_overrides:
              PreTrain:
                ++training.batch_size: 32
                ++training.gradient_accumulation_steps: 1
          ParrotSmall:
            description: CodeParrot Small
            overrides:
              ++batch_size: 200
              ++model: 'lvwerra/codeparrot-small'
            step_overrides:
              PreTrain:
                ++training.batch_size: 32
                ++training.gradient_accumulation_steps: 1
                ++training.gradient_checkpointing: True
      - Prompts:
          TitleMarker:
            description: Add at "TITLE:" before the actual Title
            hypothesis: Slight Improvement B/C of "TITLE"
            prompts.pipe:
              - name: title
          Baseline:
            description: Only the Title
            hypothesis: Baseline
            prompts.pipe:
              - name: base
          QualityAfter:
            description: The Title followed by a quality adjective based on the answers score
            hypothesis: Slight Improvement B/C of "TITLE"
            prompts.pipe:
              - name: quality_after
          AnswerYearMonth:
            description: The year and month of the answer followed by the title
            hypothesis: 'Should improve results as it handles the issue of deprecated code,
            should also be better than the question date'
            prompts.pipe:
              - name: answer_date_before
            ++processor.params.date_format_str: "%Y-%m"
          QuestionYearMonth:
            description: The year and month of the question followed by the title
            hypothesis: 'Should improve results as it handles the issue of deprecated code,
            should also be worse than the answer date'
            prompts.pipe:
              - name: question_date_before
            ++processor.params.date_format_str: "%Y-%m"
      - RemoveCode:
          OnlyCode:
            description: Remove NL from the answer and keep only code
            hypothesis: Will do better than when both modalities are kept
            ++processor.params.remove_modality: "NL"
          NLandCode:
            description: Keep Both NL and CODE in the answer
            hypothesis: Will do worse
            ++processor.params.remove_modality: NONE
    steps:
      - name: PreTrain
        description: Finetune on the SO Data
        add_name: False
        base: pretrain_with_tensorized
        group: SO
        overrides:
          ++task.buffer_size: 5000
          tracking:
            log_model: True
          is_checkpoint: False
          ++training:
            batch_size: 16
            gradient_accumulation_steps: 4
            learning_rate: 5e-5
            save_steps: 2500
            eval_steps: 500
            max_steps: 25000
            warmup_steps: 2500
            logging_steps: 25
            lr_scheduler_type: linear
            save_total_limit: 10
            group_by_length: False
            dataloader_num_workers: 4
            half_precision_backend: 'apex'
            fp16_backend: 'apex'
            gradient_checkpointing: true
            fp16_opt_level: O2
            use_8bit_adam: false
          ++task.sequence_length: 1024
          task: so
#      - name: HumanEval
#        description: Run HumanEval with the SO-finetuned model
#        add_name: False
#        base: human_eval
#        group: HUMAN_EVAL
#        overrides:
#          is_checkpoint: true
#          ++generation:
#            max_new_tokens: 256
#            do_sample: true
#            temperature: 0.5
#            top_p: 0.95
#            top_k: 50
#          model_path: outputs/so/${..__META__.PreTrain.name}/models/checkpoint-10000
#          batch_size: 200
#      - name: FineTune
#        description: Finetune on the MBPP Data
#        base: greene_config
#        group: MBPP
#        overrides:
#          task: mbpp
#          ++is_checkpoint: True
#          ++model_path: outputs/so/${..__META__.PreTrain.name}/models/checkpoint-10000
#          ++training:
#            batch_size: 32
#            gradient_accumulation_steps: 1
#            learning_rate: 5e-5
#          tracking:
#            log_model: False
#      - name: HEFineTune
#        description: Run Human Eval on the MBPP-finetuned model
#        add_name: False
#        base: human_eval
#        group: MBPP_HUMAN_EVAL
#        overrides:
#          is_checkpoint: true
#          ++generation:
#            max_new_tokens: 256
#            do_sample: true
#            temperature: 0.5
#            top_p: 0.95
#            top_k: 50
#          model_path: outputs/mbpp/${..__META__.FineTune.name}/best_model
#          batch_size: 200
#      - name: Eval
#        base: eval_config
#        description: Eval on the MBPP Data
#        group: MBPP
#        overrides:
#          batch_size: 200
#          remove_input_ids: true
#          ++generation:
#            max_new_tokens: 512
#            do_sample: true
#            temperature: 0.5
#            top_p: 0.95
#            top_k: 50
#          task: mbpp
#          remove_input_ids: true
#          ++model_path: outputs/mbpp/${..__META__.FineTune.name}/best_model
    command:
      file: templates/commands/pretrain.txt
      kwargs:
        num_return_sequences: 200
        task_name: MBPP
        train_sbatch: train_single_gpu
        pretrain_time: "23:00:00"
        use_cds: True
      fields:
        - model_path