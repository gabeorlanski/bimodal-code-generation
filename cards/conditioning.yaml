starting_commands: templates/commands/sbatch_experiment.txt
experiments:
  FullPrompt:
    overrides:
      ++device: 0
      +processor: stackoverflow
      ++raw_dump_path: data/dumps
      is_checkpoint: true
      objective: lm
      ++tracking.tags:
        - Torchrun
        - GradientCheckpointing
        - AdamW
        - O2
      ++batch_size: 200
      ++task.dump_name: python_${..__META__.ablation.name}
      ++task.raw_dump_name: python
      ++task.tensorized_name: python_${..__META__.ablation.name}
      ++processor.params.repeat_prompt_each_answer: True
      ++processor.params.repeat_body_for_each_answer: True
    ablations:
      - Model:
          Neo125M:
            overrides:
              ++batch_size: 200
              ++model: 'EleutherAI/gpt-neo-125M'
            step_overrides:
              PreTrain:
                ++training.batch_size: 32
                ++training.gradient_accumulation_steps: 1
          ParrotSmall:
            overrides:
              ++batch_size: 200
              ++model: 'lvwerra/codeparrot-small'
            step_overrides:
              PreTrain:
                ++training.batch_size: 32
                ++training.gradient_accumulation_steps: 1
                ++training.gradient_checkpointing: True
      - ProcessorArgs:
          NoPromptMeta:
            ++processor.params:
              wrap_answer_character: None
              include_date: False
              include_question_score: False
              include_tags: False
              repeat_body_for_each_answer: False
          Base:
            ++processor.params.wrap_answer_character: None
          LineComment:
            ++processor.params:
              comment_type_for_question: 'LINE'
              wrap_answer_character: "LINE"
          BlockComment:
            ++processor.params:
              comment_type_for_question: 'BLOCK'
              wrap_answer_character: "LINE"
          OnlyAnswerComment:
            ++processor.params:
              wrap_answer_character: "LINE"
          NoQuestionScore:
            ++processor.params:
              include_question_score: False
          HighestIsBest:
            ++processor.params:
              highest_is_best: True
          LowestIsBest:
            ++processor.params:
              worst_is_best: True
    steps:
      - name: PreTrain
        add_name: False
        base: pretrain_with_tensorized
        group: SO
        overrides:
          ++task.buffer_size: 5000
          ++tensorize_batch_size: 64
          tracking:
            log_model: True
          is_checkpoint: False
          ++training:
            batch_size: 16
            gradient_accumulation_steps: 4
            learning_rate: 5e-5
            save_steps: 2500
            eval_steps: 500
            max_steps: 25000
            warmup_steps: 2500
            logging_steps: 25
            lr_scheduler_type: linear
            save_total_limit: 10
            group_by_length: False
            dataloader_num_workers: 4
            half_precision_backend: 'apex'
            fp16_backend: 'apex'
            gradient_checkpointing: true
            fp16_opt_level: O2
            use_8bit_adam: False
          ++task.sequence_length: 1024
          task: so
      - name: HumanEval
        add_name: False
        base: human_eval
        group: HUMAN_EVAL
        overrides:
          is_checkpoint: true
          ++generation:
            max_new_tokens: 256
            do_sample: true
            temperature: 0.5
            top_p: 0.95
            top_k: 50
          model_path: outputs/so/${..__META__.PreTrain.name}/models/checkpoint-10000
          batch_size: 200
      - name: FineTune
        base: greene_config
        group: MBPP
        overrides:
          task: mbpp
          ++is_checkpoint: True
          ++model_path: outputs/so/${..__META__.PreTrain.name}/models/checkpoint-10000
          ++training:
            batch_size: 32
            gradient_accumulation_steps: 1
            learning_rate: 5e-5
          tracking:
            log_model: False
      - name: HEFineTune
        add_name: False
        base: human_eval
        group: MBPP_HUMAN_EVAL
        overrides:
          is_checkpoint: true
          ++generation:
            max_new_tokens: 256
            do_sample: true
            temperature: 0.5
            top_p: 0.95
            top_k: 50
          model_path: outputs/mbpp/${..__META__.FineTune.name}/best_model
          batch_size: 200
      - name: Eval
        base: eval_config
        group: MBPP
        overrides:
          batch_size: 200
          remove_input_ids: true
          ++generation:
            max_new_tokens: 512
            do_sample: true
            temperature: 0.5
            top_p: 0.95
            top_k: 50
          task: mbpp
          remove_input_ids: true
          ++model_path: outputs/mbpp/${..__META__.FineTune.name}/best_model
    command:
      file: templates/commands/execute_code.txt
      kwargs:
        num_return_sequences: 200
        task_name: MBPP
        train_sbatch: train_single_gpu
        pretrain_time: "23:00:00"
        use_cds: True
      fields:
        - model_path