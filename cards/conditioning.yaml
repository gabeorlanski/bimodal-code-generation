starting_commands: command_templates/sbatch_experiment.txt
experiments:
  Condition100K.General:
    overrides:
      ++device: 0
      +disable_cache: True
      ++tracking:
        log_model: false
      ++model: 'lvwerra/codeparrot-small'
      ++num_proc: 4
      ++training:
        batch_size: 32
        gradient_accumulation_steps: 1
      ++task.dump_name: general
      ++task.answers_per_sample: -1
    ablations:
      - RepeatQuestion:
          TitleEOS:
            ++task.repeat_question_for_each_answer: title
            ++task.use_eos_token_when_repeat: true
#          Title:
#            ++task.repeat_question_for_each_answer: title
#            ++task.use_eos_token_when_repeat: false
#          FullEOS:
#            ++task.repeat_question_for_each_answer: full
#            ++task.use_eos_token_when_repeat: true
#          Full:
#            ++task.repeat_question_for_each_answer: full
#            ++task.use_eos_token_when_repeat: false
#          NoneEOS:
#            ++task.repeat_question_for_each_answer:
#            ++task.use_eos_token_when_repeat: false
#      - AnswerPrompt:
#          APrompt:
#            ++task.answer_prompt: "A __QUALITY__ answer:"
#          NoAPrompt:
#            ++task.answer_prompt:
#      - QuestionPrompt:
#          QPrompt:
#            ++task.question_prompt: "Given the question: __TITLE__
#
#            __BODY__"
#          NoQPrompt:
#            ++task.question_prompt:


    steps:
      - name: PreTrain
        base: pretrain_config
        group: SO
        overrides:
          objective: 'lm'
          training:
            learning_rate: 1e-3
            max_steps: -1
          tracking:
            log_model: true
          task: so
          ++task.max_samples: 100000
          ++task.max_val_samples: 250
      - name: FineTune
        base: condition_finetune
        group: MBPP
        overrides:
          objective: 'lm'
          task: mbpp
          ++is_checkpoint: True
          ++model_path: best_models/${..__META__.previous_step.save_name}
          training:
            learning_rate: 5e-5
      - name: Eval
        base: eval_config
        group: MBPP
        overrides:
          batch_size: 200
          remove_input_ids: true
          ++generation:
            max_new_tokens: 256
          ++device: 0
          task: mbpp
          remove_input_ids: true
          ++model_path: best_models/${..__META__.previous_step.save_name}
    command:
      file: command_templates/pretrain_then_finetune.txt
      kwargs:
        num_return_sequences: 200
        task_name: MBPP
        train_sbatch: train_single_gpu
      fields:
        - model_path